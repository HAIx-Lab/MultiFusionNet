{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53fbc15",
      "metadata": {
        "id": "f53fbc15"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, concatenate, Flatten, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.applications.inception_v3 import InceptionV3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c9b3c5",
      "metadata": {
        "id": "d0c9b3c5"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
        "\n",
        "batch_size = 32\n",
        "img_height, img_width = 224, 224\n",
        "input_shape = (img_height, img_width, 3)\n",
        "epochs = 100\n",
        "input_tensor = Input(shape = input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e8003e",
      "metadata": {
        "id": "98e8003e",
        "outputId": "5c6cb843-67e0-4949-b5f2-48e379815b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 0s 0us/step\n",
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model1=ResNet50V2(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "for layer in base_model1.layers:\n",
        "  layer.trainable=False\n",
        "base_model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4b66e9",
      "metadata": {
        "id": "1d4b66e9",
        "outputId": "c77d1115-9f10-4e1c-a054-c7a8cba0a6b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 128)\n",
            "(None, 7, 7, 1024)\n",
            "(None, 7, 7, 512)\n",
            "(None, 7, 7, 256)\n",
            "(None, 7, 7, 1920)\n"
          ]
        }
      ],
      "source": [
        "#a=base_model1.get_layer(\"conv5_block2_3_conv\").outputconv3_block3_2_conv\n",
        "a=base_model1.get_layer(\"conv3_block3_2_conv\").output\n",
        "a=MaxPooling2D()(a)\n",
        "a=MaxPooling2D()(a)\n",
        "b=base_model1.get_layer(\"conv4_block6_3_conv\").output\n",
        "c=base_model1.get_layer(\"conv3_block4_3_conv\").output\n",
        "c=MaxPooling2D()(c)\n",
        "d=base_model1.get_layer(\"conv2_block3_3_conv\").output\n",
        "d=MaxPooling2D()(d)\n",
        "d=MaxPooling2D()(d)\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(d.shape)\n",
        "abcd=concatenate([a,b,c,d], axis=-1)\n",
        "print(abcd.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f735d462",
      "metadata": {
        "id": "f735d462",
        "outputId": "046d7950-03dc-478f-a7bb-7ed0b148655e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 2048)\n"
          ]
        }
      ],
      "source": [
        "y = base_model1.output\n",
        "conc=concatenate([y,abcd], axis=-1)\n",
        "conc=BatchNormalization()(conc)\n",
        "conc=Conv2D(2048, (1,1), activation='relu')(conc)\n",
        "conc = GlobalAveragePooling2D()(conc)\n",
        "print(conc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71e92a3",
      "metadata": {
        "id": "f71e92a3",
        "outputId": "c1ecbc46-bb96-4f15-e30d-952b8afa5e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d_2[0][0]']               \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 54, 54, 64)  0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_7[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate_2[0][0]',          \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_3[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model2=InceptionV3(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "for layer in base_model2.layers:\n",
        "  layer.trainable=False\n",
        "base_model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91318ce2",
      "metadata": {
        "id": "91318ce2",
        "outputId": "606d89fd-b9cf-4bcd-f41d-65154194e92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 4096)\n"
          ]
        }
      ],
      "source": [
        "T=concatenate([conc,conc1], axis=-1)\n",
        "print(T.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_specific_features(inputs):\n",
        "    feature1 = inputs[0]\n",
        "    feature2 = inputs[1]\n",
        "    added_features = feature1 + feature2\n",
        "    return added_features\n",
        "\n",
        "added_features = Lambda(add_specific_features)([conc, conc1])"
      ],
      "metadata": {
        "id": "lIzsZha899Mg"
      },
      "id": "lIzsZha899Mg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Dropout\n",
        "print(added_features.shape)\n",
        "T=Dropout(0.3)(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PsAUQD6-Fon",
        "outputId": "98a55d89-5760-4b79-d5a1-37af46c74235"
      },
      "id": "6PsAUQD6-Fon",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc3e43a",
      "metadata": {
        "id": "7bc3e43a",
        "outputId": "8183dc20-b2bf-4939-95c8-026067ec1ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d_2[0][0]']               \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 54, 54, 64)  0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_7[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate_2[0][0]',          \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_36 (MaxPooling2D  (None, 14, 14, 128)  0          ['conv3_block3_2_conv[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_39 (MaxPooling2D  (None, 14, 14, 256)  0          ['conv2_block3_3_conv[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_37 (MaxPooling2D  (None, 7, 7, 128)   0           ['max_pooling2d_36[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_38 (MaxPooling2D  (None, 7, 7, 512)   0           ['conv3_block4_3_conv[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_40 (MaxPooling2D  (None, 7, 7, 256)   0           ['max_pooling2d_39[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 7, 7, 1920)   0           ['max_pooling2d_37[0][0]',       \n",
            "                                                                  'conv4_block6_3_conv[0][0]',    \n",
            "                                                                  'max_pooling2d_38[0][0]',       \n",
            "                                                                  'max_pooling2d_40[0][0]']       \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_3[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 5, 5, 1536)   0           ['conv2d_92[0][0]',              \n",
            "                                                                  'conv2d_88[0][0]',              \n",
            "                                                                  'conv2d_80[0][0]',              \n",
            "                                                                  'conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 7, 7, 3968)   0           ['post_relu[0][0]',              \n",
            "                                                                  'concatenate_18[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 5, 5, 3584)   0           ['mixed10[0][0]',                \n",
            "                                                                  'concatenate_24[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 7, 7, 3968)  15872       ['concatenate_19[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 5, 5, 3584)  14336       ['concatenate_25[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 7, 7, 2048)   8128512     ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 5, 5, 2048)   7342080     ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " global_average_pooling2d_4 (Gl  (None, 2048)        0           ['conv2d_102[0][0]']             \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_7 (Gl  (None, 2048)        0           ['conv2d_105[0][0]']             \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 2048)         0           ['global_average_pooling2d_4[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_average_pooling2d_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          524544      ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            771         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,393,699\n",
            "Trainable params: 16,011,011\n",
            "Non-trainable params: 45,382,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "T = Dense(256, activation='relu')(added_features)\n",
        "predictions1 = Dense(3, activation='softmax')(T)\n",
        "model3 = Model(inputs=input_tensor,outputs=predictions1)\n",
        "model3.summary()\n",
        "model3.compile(loss='CategoricalCrossentropy',optimizer='adam',metrics=['acc'] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trainable Parameters:\")\n",
        "for layer in model3.trainable_weights:\n",
        "    print(layer.name)\n",
        "\n",
        "print(model3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE8MFmIE4j5I",
        "outputId": "2b7c266b-3c4e-49d3-c9ba-a768406ed573"
      },
      "id": "CE8MFmIE4j5I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Parameters:\n",
            "batch_normalization_105/gamma:0\n",
            "batch_normalization_105/beta:0\n",
            "batch_normalization_106/gamma:0\n",
            "batch_normalization_106/beta:0\n",
            "batch_normalization_107/gamma:0\n",
            "batch_normalization_107/beta:0\n",
            "batch_normalization_108/gamma:0\n",
            "batch_normalization_108/beta:0\n",
            "conv2d/kernel:0\n",
            "conv2d/bias:0\n",
            "batch_normalization_109/gamma:0\n",
            "batch_normalization_109/beta:0\n",
            "conv2d_1/kernel:0\n",
            "conv2d_1/bias:0\n",
            "conv2d_98/kernel:0\n",
            "conv2d_98/bias:0\n",
            "dense/kernel:0\n",
            "dense/bias:0\n",
            "dense_1/kernel:0\n",
            "dense_1/bias:0\n",
            "<keras.engine.functional.Functional object at 0x7f235a06d3f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trainable Layers:\")\n",
        "for layer in model3.layers:\n",
        "    if layer.trainable:\n",
        "        print(layer.name)\n",
        "        print(layer.count_params())\n",
        "        print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8As1uiQ5vhh",
        "outputId": "f83c6ed7-c3f4-4118-840d-78d1af51eb18"
      },
      "id": "H8As1uiQ5vhh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Layers:\n",
            "max_pooling2d_36\n",
            "0\n",
            "---\n",
            "max_pooling2d_39\n",
            "0\n",
            "---\n",
            "max_pooling2d_37\n",
            "0\n",
            "---\n",
            "max_pooling2d_38\n",
            "0\n",
            "---\n",
            "max_pooling2d_40\n",
            "0\n",
            "---\n",
            "concatenate_18\n",
            "0\n",
            "---\n",
            "concatenate_24\n",
            "0\n",
            "---\n",
            "concatenate_19\n",
            "0\n",
            "---\n",
            "concatenate_25\n",
            "0\n",
            "---\n",
            "batch_normalization_112\n",
            "15872\n",
            "---\n",
            "batch_normalization_115\n",
            "14336\n",
            "---\n",
            "conv2d_102\n",
            "8128512\n",
            "---\n",
            "conv2d_105\n",
            "7342080\n",
            "---\n",
            "global_average_pooling2d_4\n",
            "0\n",
            "---\n",
            "global_average_pooling2d_7\n",
            "0\n",
            "---\n",
            "lambda\n",
            "0\n",
            "---\n",
            "dense_2\n",
            "524544\n",
            "---\n",
            "dense_3\n",
            "771\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trainable Layers:\")\n",
        "for layer in model3.layers:\n",
        "    if layer.trainable:\n",
        "        print(layer.name)\n",
        "        print(layer.output_shape)\n",
        "        print(layer.count_params())\n",
        "        print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zRExhYO6Fgf",
        "outputId": "5a0344b1-dc34-4816-c906-7a6488b0a01f"
      },
      "id": "8zRExhYO6Fgf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Layers:\n",
            "max_pooling2d_36\n",
            "(None, 14, 14, 128)\n",
            "0\n",
            "---\n",
            "max_pooling2d_39\n",
            "(None, 14, 14, 256)\n",
            "0\n",
            "---\n",
            "max_pooling2d_37\n",
            "(None, 7, 7, 128)\n",
            "0\n",
            "---\n",
            "max_pooling2d_38\n",
            "(None, 7, 7, 512)\n",
            "0\n",
            "---\n",
            "max_pooling2d_40\n",
            "(None, 7, 7, 256)\n",
            "0\n",
            "---\n",
            "concatenate_18\n",
            "(None, 7, 7, 1920)\n",
            "0\n",
            "---\n",
            "concatenate_24\n",
            "(None, 5, 5, 1536)\n",
            "0\n",
            "---\n",
            "concatenate_19\n",
            "(None, 7, 7, 3968)\n",
            "0\n",
            "---\n",
            "concatenate_25\n",
            "(None, 5, 5, 3584)\n",
            "0\n",
            "---\n",
            "batch_normalization_112\n",
            "(None, 7, 7, 3968)\n",
            "15872\n",
            "---\n",
            "batch_normalization_115\n",
            "(None, 5, 5, 3584)\n",
            "14336\n",
            "---\n",
            "conv2d_102\n",
            "(None, 7, 7, 2048)\n",
            "8128512\n",
            "---\n",
            "conv2d_105\n",
            "(None, 5, 5, 2048)\n",
            "7342080\n",
            "---\n",
            "global_average_pooling2d_4\n",
            "(None, 2048)\n",
            "0\n",
            "---\n",
            "global_average_pooling2d_7\n",
            "(None, 2048)\n",
            "0\n",
            "---\n",
            "lambda\n",
            "(None, 2048)\n",
            "0\n",
            "---\n",
            "dense_2\n",
            "(None, 256)\n",
            "524544\n",
            "---\n",
            "dense_3\n",
            "(None, 3)\n",
            "771\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model3.layers:\n",
        "    if layer.trainable:\n",
        "        print(layer.name)\n",
        "        print(\"Number of Parameters:\", layer.count_params())\n",
        "        if isinstance(layer, Conv2D):\n",
        "            print(\"Kernel Size:\", layer.kernel_size)\n",
        "        print(\"Output Size:\", layer.output_shape)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icy3zghTAr93",
        "outputId": "3c7a8842-ad30-4a77-b8ec-3ba47112cbbf"
      },
      "id": "icy3zghTAr93",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_pooling2d_36\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 14, 14, 128)\n",
            "\n",
            "max_pooling2d_39\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 14, 14, 256)\n",
            "\n",
            "max_pooling2d_37\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 7, 7, 128)\n",
            "\n",
            "max_pooling2d_38\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 7, 7, 512)\n",
            "\n",
            "max_pooling2d_40\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 7, 7, 256)\n",
            "\n",
            "concatenate_18\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 7, 7, 1920)\n",
            "\n",
            "concatenate_24\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 5, 5, 1536)\n",
            "\n",
            "concatenate_19\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 7, 7, 3968)\n",
            "\n",
            "concatenate_25\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 5, 5, 3584)\n",
            "\n",
            "batch_normalization_112\n",
            "Number of Parameters: 15872\n",
            "Output Size: (None, 7, 7, 3968)\n",
            "\n",
            "batch_normalization_115\n",
            "Number of Parameters: 14336\n",
            "Output Size: (None, 5, 5, 3584)\n",
            "\n",
            "conv2d_102\n",
            "Number of Parameters: 8128512\n",
            "Kernel Size: (1, 1)\n",
            "Output Size: (None, 7, 7, 2048)\n",
            "\n",
            "conv2d_105\n",
            "Number of Parameters: 7342080\n",
            "Kernel Size: (1, 1)\n",
            "Output Size: (None, 5, 5, 2048)\n",
            "\n",
            "global_average_pooling2d_4\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 2048)\n",
            "\n",
            "global_average_pooling2d_7\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 2048)\n",
            "\n",
            "lambda\n",
            "Number of Parameters: 0\n",
            "Output Size: (None, 2048)\n",
            "\n",
            "dense_2\n",
            "Number of Parameters: 524544\n",
            "Output Size: (None, 256)\n",
            "\n",
            "dense_3\n",
            "Number of Parameters: 771\n",
            "Output Size: (None, 3)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41293de",
      "metadata": {
        "id": "f41293de",
        "outputId": "20a24475-efec-4502-d42b-8045618aa62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12157 images belonging to 3 classes.\n",
            "Found 3219 images belonging to 3 classes.\n",
            "ln: failed to create symbolic link '/usr/bin/nvidia-smi': Permission denied\n",
            "Requirement already satisfied: psutil in ./anaconda3/lib/python3.8/site-packages (5.8.0)\n",
            "Requirement already satisfied: humanize in ./anaconda3/lib/python3.8/site-packages (3.10.0)\n",
            "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.8/site-packages (from humanize) (52.0.0.post20210125)\n",
            "Gen RAM Free: 1.6 GB  |     Proc size: 1.2 GB\n"
          ]
        }
      ],
      "source": [
        "training_data_dir='/home/iiitm/Desktop/Dataset/train'\n",
        "training_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "training_generator = training_data_generator.flow_from_directory(\n",
        "    training_data_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\")\n",
        "validation_data_dir='/home/iiitm/Desktop/Dataset/validation'\n",
        "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_data_generator.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False)\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# XXX: only one GPU on Colab and isnt guaranteed\n",
        "\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "\n",
        "printm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce958a1",
      "metadata": {
        "id": "fce958a1"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath = \"/home/iiitm/Desktop/march22/saved-model-{epoch:02d}-{loss:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min', save_freq = 'epoch' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87248c65",
      "metadata": {
        "id": "87248c65",
        "outputId": "ee16c5cb-7b28-4970-b61e-d9f8dcda94ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.3263 - acc: 0.8987\n",
            "Epoch 1: saving model to /home/iiitm/Desktop/march22/saved-model-01-0.33.hdf5\n",
            "380/380 [==============================] - 1472s 4s/step - loss: 0.3263 - acc: 0.8987 - val_loss: 0.4034 - val_acc: 0.8487\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1823 - acc: 0.9330\n",
            "Epoch 2: saving model to /home/iiitm/Desktop/march22/saved-model-02-0.18.hdf5\n",
            "380/380 [==============================] - 1172s 3s/step - loss: 0.1823 - acc: 0.9330 - val_loss: 0.2201 - val_acc: 0.9080\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1546 - acc: 0.9421\n",
            "Epoch 3: saving model to /home/iiitm/Desktop/march22/saved-model-03-0.15.hdf5\n",
            "380/380 [==============================] - 1093s 3s/step - loss: 0.1546 - acc: 0.9421 - val_loss: 0.2673 - val_acc: 0.8910\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9425\n",
            "Epoch 4: saving model to /home/iiitm/Desktop/march22/saved-model-04-0.15.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.1522 - acc: 0.9425 - val_loss: 0.3252 - val_acc: 0.8823\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1389 - acc: 0.9485\n",
            "Epoch 5: saving model to /home/iiitm/Desktop/march22/saved-model-05-0.14.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.1389 - acc: 0.9485 - val_loss: 0.1797 - val_acc: 0.9310\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1285 - acc: 0.9517\n",
            "Epoch 6: saving model to /home/iiitm/Desktop/march22/saved-model-06-0.13.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.1285 - acc: 0.9517 - val_loss: 0.2050 - val_acc: 0.9211\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.9584\n",
            "Epoch 7: saving model to /home/iiitm/Desktop/march22/saved-model-07-0.11.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.1059 - acc: 0.9584 - val_loss: 0.4221 - val_acc: 0.8571\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1111 - acc: 0.9597\n",
            "Epoch 8: saving model to /home/iiitm/Desktop/march22/saved-model-08-0.11.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.1111 - acc: 0.9597 - val_loss: 0.3520 - val_acc: 0.8767\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1010 - acc: 0.9624\n",
            "Epoch 9: saving model to /home/iiitm/Desktop/march22/saved-model-09-0.10.hdf5\n",
            "380/380 [==============================] - 1089s 3s/step - loss: 0.1010 - acc: 0.9624 - val_loss: 0.1645 - val_acc: 0.9391\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.1039 - acc: 0.9614\n",
            "Epoch 10: saving model to /home/iiitm/Desktop/march22/saved-model-10-0.10.hdf5\n",
            "380/380 [==============================] - 1090s 3s/step - loss: 0.1039 - acc: 0.9614 - val_loss: 0.1715 - val_acc: 0.9329\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0953 - acc: 0.9655\n",
            "Epoch 11: saving model to /home/iiitm/Desktop/march22/saved-model-11-0.10.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0953 - acc: 0.9655 - val_loss: 0.1686 - val_acc: 0.9404\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0852 - acc: 0.9701\n",
            "Epoch 12: saving model to /home/iiitm/Desktop/march22/saved-model-12-0.09.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.0852 - acc: 0.9701 - val_loss: 0.2640 - val_acc: 0.9127\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0810 - acc: 0.9702\n",
            "Epoch 13: saving model to /home/iiitm/Desktop/march22/saved-model-13-0.08.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0810 - acc: 0.9702 - val_loss: 0.2102 - val_acc: 0.9254\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.9717\n",
            "Epoch 14: saving model to /home/iiitm/Desktop/march22/saved-model-14-0.08.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0783 - acc: 0.9717 - val_loss: 0.2183 - val_acc: 0.9239\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0795 - acc: 0.9706\n",
            "Epoch 15: saving model to /home/iiitm/Desktop/march22/saved-model-15-0.08.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0795 - acc: 0.9706 - val_loss: 0.2380 - val_acc: 0.9208\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0698 - acc: 0.9740\n",
            "Epoch 16: saving model to /home/iiitm/Desktop/march22/saved-model-16-0.07.hdf5\n",
            "380/380 [==============================] - 1089s 3s/step - loss: 0.0698 - acc: 0.9740 - val_loss: 0.2644 - val_acc: 0.9139\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9757\n",
            "Epoch 17: saving model to /home/iiitm/Desktop/march22/saved-model-17-0.07.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0658 - acc: 0.9757 - val_loss: 0.3375 - val_acc: 0.8922\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.9721\n",
            "Epoch 18: saving model to /home/iiitm/Desktop/march22/saved-model-18-0.07.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.0712 - acc: 0.9721 - val_loss: 0.2815 - val_acc: 0.8987\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9781\n",
            "Epoch 19: saving model to /home/iiitm/Desktop/march22/saved-model-19-0.06.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0574 - acc: 0.9781 - val_loss: 0.2753 - val_acc: 0.9258\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0630 - acc: 0.9777\n",
            "Epoch 20: saving model to /home/iiitm/Desktop/march22/saved-model-20-0.06.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.0630 - acc: 0.9777 - val_loss: 0.1878 - val_acc: 0.9385\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.9761\n",
            "Epoch 21: saving model to /home/iiitm/Desktop/march22/saved-model-21-0.06.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0601 - acc: 0.9761 - val_loss: 0.2065 - val_acc: 0.9310\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0578 - acc: 0.9790\n",
            "Epoch 22: saving model to /home/iiitm/Desktop/march22/saved-model-22-0.06.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0578 - acc: 0.9790 - val_loss: 0.2596 - val_acc: 0.9199\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0598 - acc: 0.9777\n",
            "Epoch 23: saving model to /home/iiitm/Desktop/march22/saved-model-23-0.06.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0598 - acc: 0.9777 - val_loss: 0.2721 - val_acc: 0.9152\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0602 - acc: 0.9783\n",
            "Epoch 24: saving model to /home/iiitm/Desktop/march22/saved-model-24-0.06.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0602 - acc: 0.9783 - val_loss: 0.1975 - val_acc: 0.9382\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0582 - acc: 0.9783\n",
            "Epoch 25: saving model to /home/iiitm/Desktop/march22/saved-model-25-0.06.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0582 - acc: 0.9783 - val_loss: 0.3007 - val_acc: 0.9133\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.9775\n",
            "Epoch 26: saving model to /home/iiitm/Desktop/march22/saved-model-26-0.06.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.0605 - acc: 0.9775 - val_loss: 0.1718 - val_acc: 0.9472\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0536 - acc: 0.9806\n",
            "Epoch 27: saving model to /home/iiitm/Desktop/march22/saved-model-27-0.05.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0536 - acc: 0.9806 - val_loss: 0.4139 - val_acc: 0.8903\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0443 - acc: 0.9844\n",
            "Epoch 28: saving model to /home/iiitm/Desktop/march22/saved-model-28-0.04.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0443 - acc: 0.9844 - val_loss: 0.2035 - val_acc: 0.9422\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9810\n",
            "Epoch 29: saving model to /home/iiitm/Desktop/march22/saved-model-29-0.05.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0532 - acc: 0.9810 - val_loss: 0.2365 - val_acc: 0.9329\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.9826\n",
            "Epoch 30: saving model to /home/iiitm/Desktop/march22/saved-model-30-0.05.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0496 - acc: 0.9826 - val_loss: 0.2724 - val_acc: 0.9323\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0520 - acc: 0.9801\n",
            "Epoch 31: saving model to /home/iiitm/Desktop/march22/saved-model-31-0.05.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0520 - acc: 0.9801 - val_loss: 0.4738 - val_acc: 0.8692\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0436 - acc: 0.9836\n",
            "Epoch 32: saving model to /home/iiitm/Desktop/march22/saved-model-32-0.04.hdf5\n",
            "380/380 [==============================] - 1089s 3s/step - loss: 0.0436 - acc: 0.9836 - val_loss: 0.1914 - val_acc: 0.9435\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.9825\n",
            "Epoch 33: saving model to /home/iiitm/Desktop/march22/saved-model-33-0.05.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0463 - acc: 0.9825 - val_loss: 0.2943 - val_acc: 0.9118\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.9844\n",
            "Epoch 34: saving model to /home/iiitm/Desktop/march22/saved-model-34-0.04.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0399 - acc: 0.9844 - val_loss: 0.2086 - val_acc: 0.9388\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0349 - acc: 0.9876\n",
            "Epoch 35: saving model to /home/iiitm/Desktop/march22/saved-model-35-0.03.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0349 - acc: 0.9876 - val_loss: 0.2168 - val_acc: 0.9382\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9827\n",
            "Epoch 36: saving model to /home/iiitm/Desktop/march22/saved-model-36-0.05.hdf5\n",
            "380/380 [==============================] - 1129s 3s/step - loss: 0.0473 - acc: 0.9827 - val_loss: 0.2770 - val_acc: 0.9217\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.9842\n",
            "Epoch 37: saving model to /home/iiitm/Desktop/march22/saved-model-37-0.04.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0412 - acc: 0.9842 - val_loss: 0.3576 - val_acc: 0.9115\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0316 - acc: 0.9877\n",
            "Epoch 38: saving model to /home/iiitm/Desktop/march22/saved-model-38-0.03.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0316 - acc: 0.9877 - val_loss: 0.3570 - val_acc: 0.9189\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0423 - acc: 0.9841\n",
            "Epoch 39: saving model to /home/iiitm/Desktop/march22/saved-model-39-0.04.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0423 - acc: 0.9841 - val_loss: 0.2383 - val_acc: 0.9317\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0310 - acc: 0.9896\n",
            "Epoch 40: saving model to /home/iiitm/Desktop/march22/saved-model-40-0.03.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.1614 - val_acc: 0.9531\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0298 - acc: 0.9895\n",
            "Epoch 41: saving model to /home/iiitm/Desktop/march22/saved-model-41-0.03.hdf5\n",
            "380/380 [==============================] - 1091s 3s/step - loss: 0.0298 - acc: 0.9895 - val_loss: 0.2558 - val_acc: 0.9248\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0320 - acc: 0.9876\n",
            "Epoch 42: saving model to /home/iiitm/Desktop/march22/saved-model-42-0.03.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0320 - acc: 0.9876 - val_loss: 0.2390 - val_acc: 0.9400\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9840\n",
            "Epoch 43: saving model to /home/iiitm/Desktop/march22/saved-model-43-0.04.hdf5\n",
            "380/380 [==============================] - 1081s 3s/step - loss: 0.0437 - acc: 0.9840 - val_loss: 0.2979 - val_acc: 0.9161\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.9885\n",
            "Epoch 44: saving model to /home/iiitm/Desktop/march22/saved-model-44-0.03.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0314 - acc: 0.9885 - val_loss: 0.2424 - val_acc: 0.9394\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0302 - acc: 0.9883\n",
            "Epoch 45: saving model to /home/iiitm/Desktop/march22/saved-model-45-0.03.hdf5\n",
            "380/380 [==============================] - 1092s 3s/step - loss: 0.0302 - acc: 0.9883 - val_loss: 0.3200 - val_acc: 0.8869\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9867\n",
            "Epoch 46: saving model to /home/iiitm/Desktop/march22/saved-model-46-0.03.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.0344 - acc: 0.9867 - val_loss: 0.1995 - val_acc: 0.9419\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9885\n",
            "Epoch 47: saving model to /home/iiitm/Desktop/march22/saved-model-47-0.04.hdf5\n",
            "380/380 [==============================] - 1098s 3s/step - loss: 0.0353 - acc: 0.9885 - val_loss: 0.2353 - val_acc: 0.9351\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0323 - acc: 0.9886\n",
            "Epoch 48: saving model to /home/iiitm/Desktop/march22/saved-model-48-0.03.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0323 - acc: 0.9886 - val_loss: 0.2455 - val_acc: 0.9326\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0363 - acc: 0.9877\n",
            "Epoch 49: saving model to /home/iiitm/Desktop/march22/saved-model-49-0.04.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0363 - acc: 0.9877 - val_loss: 0.2577 - val_acc: 0.9261\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0288 - acc: 0.9883\n",
            "Epoch 50: saving model to /home/iiitm/Desktop/march22/saved-model-50-0.03.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0288 - acc: 0.9883 - val_loss: 0.1409 - val_acc: 0.9599\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0319 - acc: 0.9868\n",
            "Epoch 51: saving model to /home/iiitm/Desktop/march22/saved-model-51-0.03.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0319 - acc: 0.9868 - val_loss: 0.1485 - val_acc: 0.9578\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9896\n",
            "Epoch 52: saving model to /home/iiitm/Desktop/march22/saved-model-52-0.03.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0297 - acc: 0.9896 - val_loss: 0.1549 - val_acc: 0.9559\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0267 - acc: 0.9902\n",
            "Epoch 53: saving model to /home/iiitm/Desktop/march22/saved-model-53-0.03.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.0267 - acc: 0.9902 - val_loss: 0.2394 - val_acc: 0.9404\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9907\n",
            "Epoch 54: saving model to /home/iiitm/Desktop/march22/saved-model-54-0.02.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0250 - acc: 0.9907 - val_loss: 0.2735 - val_acc: 0.9329\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9912\n",
            "Epoch 55: saving model to /home/iiitm/Desktop/march22/saved-model-55-0.03.hdf5\n",
            "380/380 [==============================] - 1089s 3s/step - loss: 0.0253 - acc: 0.9912 - val_loss: 0.3041 - val_acc: 0.9335\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9915\n",
            "Epoch 56: saving model to /home/iiitm/Desktop/march22/saved-model-56-0.03.hdf5\n",
            "380/380 [==============================] - 1090s 3s/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.1839 - val_acc: 0.9525\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.9878\n",
            "Epoch 57: saving model to /home/iiitm/Desktop/march22/saved-model-57-0.03.hdf5\n",
            "380/380 [==============================] - 1092s 3s/step - loss: 0.0339 - acc: 0.9878 - val_loss: 0.2468 - val_acc: 0.9432\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0270 - acc: 0.9893\n",
            "Epoch 58: saving model to /home/iiitm/Desktop/march22/saved-model-58-0.03.hdf5\n",
            "380/380 [==============================] - 1090s 3s/step - loss: 0.0270 - acc: 0.9893 - val_loss: 0.2496 - val_acc: 0.9348\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0280 - acc: 0.9888\n",
            "Epoch 59: saving model to /home/iiitm/Desktop/march22/saved-model-59-0.03.hdf5\n",
            "380/380 [==============================] - 1086s 3s/step - loss: 0.0280 - acc: 0.9888 - val_loss: 0.2299 - val_acc: 0.9419\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0300 - acc: 0.9898\n",
            "Epoch 60: saving model to /home/iiitm/Desktop/march22/saved-model-60-0.03.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0300 - acc: 0.9898 - val_loss: 0.2085 - val_acc: 0.9413\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.9900\n",
            "Epoch 61: saving model to /home/iiitm/Desktop/march22/saved-model-61-0.03.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.0275 - acc: 0.9900 - val_loss: 0.2099 - val_acc: 0.9515\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0254 - acc: 0.9905\n",
            "Epoch 62: saving model to /home/iiitm/Desktop/march22/saved-model-62-0.03.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.0254 - acc: 0.9905 - val_loss: 0.2465 - val_acc: 0.9385\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.9883\n",
            "Epoch 63: saving model to /home/iiitm/Desktop/march22/saved-model-63-0.03.hdf5\n",
            "380/380 [==============================] - 1087s 3s/step - loss: 0.0313 - acc: 0.9883 - val_loss: 0.4355 - val_acc: 0.9155\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9909\n",
            "Epoch 64: saving model to /home/iiitm/Desktop/march22/saved-model-64-0.03.hdf5\n",
            "380/380 [==============================] - 1088s 3s/step - loss: 0.0265 - acc: 0.9909 - val_loss: 0.1770 - val_acc: 0.9568\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0305 - acc: 0.9888\n",
            "Epoch 65: saving model to /home/iiitm/Desktop/march22/saved-model-65-0.03.hdf5\n",
            "380/380 [==============================] - 1083s 3s/step - loss: 0.0305 - acc: 0.9888 - val_loss: 0.2941 - val_acc: 0.9335\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9921\n",
            "Epoch 66: saving model to /home/iiitm/Desktop/march22/saved-model-66-0.02.hdf5\n",
            "380/380 [==============================] - 1085s 3s/step - loss: 0.0220 - acc: 0.9921 - val_loss: 0.1736 - val_acc: 0.9574\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.9924\n",
            "Epoch 67: saving model to /home/iiitm/Desktop/march22/saved-model-67-0.02.hdf5\n",
            "380/380 [==============================] - 1090s 3s/step - loss: 0.0194 - acc: 0.9924 - val_loss: 0.2248 - val_acc: 0.9450\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9931\n",
            "Epoch 68: saving model to /home/iiitm/Desktop/march22/saved-model-68-0.02.hdf5\n",
            "380/380 [==============================] - 1080s 3s/step - loss: 0.0179 - acc: 0.9931 - val_loss: 0.1971 - val_acc: 0.9509\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0257 - acc: 0.9909\n",
            "Epoch 69: saving model to /home/iiitm/Desktop/march22/saved-model-69-0.03.hdf5\n",
            "380/380 [==============================] - 1084s 3s/step - loss: 0.0257 - acc: 0.9909 - val_loss: 0.2217 - val_acc: 0.9453\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.9946\n",
            "Epoch 70: saving model to /home/iiitm/Desktop/march22/saved-model-70-0.02.hdf5\n",
            "380/380 [==============================] - 1082s 3s/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.2709 - val_acc: 0.9413\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0256 - acc: 0.9910\n",
            "Epoch 71: saving model to /home/iiitm/Desktop/march22/saved-model-71-0.03.hdf5\n",
            "380/380 [==============================] - 1111s 3s/step - loss: 0.0256 - acc: 0.9910 - val_loss: 0.2059 - val_acc: 0.9463\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0300 - acc: 0.9887\n",
            "Epoch 72: saving model to /home/iiitm/Desktop/march22/saved-model-72-0.03.hdf5\n",
            "380/380 [==============================] - 1410s 4s/step - loss: 0.0300 - acc: 0.9887 - val_loss: 0.1713 - val_acc: 0.9571\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9924\n",
            "Epoch 73: saving model to /home/iiitm/Desktop/march22/saved-model-73-0.02.hdf5\n",
            "380/380 [==============================] - 1143s 3s/step - loss: 0.0200 - acc: 0.9924 - val_loss: 0.2129 - val_acc: 0.9494\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0234 - acc: 0.9921\n",
            "Epoch 74: saving model to /home/iiitm/Desktop/march22/saved-model-74-0.02.hdf5\n",
            "380/380 [==============================] - 1105s 3s/step - loss: 0.0234 - acc: 0.9921 - val_loss: 0.2615 - val_acc: 0.9341\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9942\n",
            "Epoch 75: saving model to /home/iiitm/Desktop/march22/saved-model-75-0.02.hdf5\n",
            "380/380 [==============================] - 1152s 3s/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.2076 - val_acc: 0.9503\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0256 - acc: 0.9896\n",
            "Epoch 76: saving model to /home/iiitm/Desktop/march22/saved-model-76-0.03.hdf5\n",
            "380/380 [==============================] - 1166s 3s/step - loss: 0.0256 - acc: 0.9896 - val_loss: 0.2128 - val_acc: 0.9494\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.9921\n",
            "Epoch 77: saving model to /home/iiitm/Desktop/march22/saved-model-77-0.02.hdf5\n",
            "380/380 [==============================] - 1217s 3s/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.3823 - val_acc: 0.9127\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0241 - acc: 0.9917\n",
            "Epoch 78: saving model to /home/iiitm/Desktop/march22/saved-model-78-0.02.hdf5\n",
            "380/380 [==============================] - 1240s 3s/step - loss: 0.0241 - acc: 0.9917 - val_loss: 0.1996 - val_acc: 0.9546\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9910\n",
            "Epoch 79: saving model to /home/iiitm/Desktop/march22/saved-model-79-0.03.hdf5\n",
            "380/380 [==============================] - 1189s 3s/step - loss: 0.0265 - acc: 0.9910 - val_loss: 0.2241 - val_acc: 0.9444\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0215 - acc: 0.9919\n",
            "Epoch 80: saving model to /home/iiitm/Desktop/march22/saved-model-80-0.02.hdf5\n",
            "380/380 [==============================] - 1311s 3s/step - loss: 0.0215 - acc: 0.9919 - val_loss: 0.3190 - val_acc: 0.9320\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9945\n",
            "Epoch 81: saving model to /home/iiitm/Desktop/march22/saved-model-81-0.02.hdf5\n",
            "380/380 [==============================] - 1245s 3s/step - loss: 0.0151 - acc: 0.9945 - val_loss: 0.1895 - val_acc: 0.9550\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9933\n",
            "Epoch 82: saving model to /home/iiitm/Desktop/march22/saved-model-82-0.02.hdf5\n",
            "380/380 [==============================] - 1466s 4s/step - loss: 0.0198 - acc: 0.9933 - val_loss: 0.2060 - val_acc: 0.9463\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9918\n",
            "Epoch 83: saving model to /home/iiitm/Desktop/march22/saved-model-83-0.02.hdf5\n",
            "380/380 [==============================] - 1295s 3s/step - loss: 0.0198 - acc: 0.9918 - val_loss: 0.5035 - val_acc: 0.8978\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0197 - acc: 0.9943\n",
            "Epoch 84: saving model to /home/iiitm/Desktop/march22/saved-model-84-0.02.hdf5\n",
            "380/380 [==============================] - 1134s 3s/step - loss: 0.0197 - acc: 0.9943 - val_loss: 0.1807 - val_acc: 0.9584\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9898\n",
            "Epoch 85: saving model to /home/iiitm/Desktop/march22/saved-model-85-0.03.hdf5\n",
            "380/380 [==============================] - 1118s 3s/step - loss: 0.0277 - acc: 0.9898 - val_loss: 0.2335 - val_acc: 0.9491\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0197 - acc: 0.9927\n",
            "Epoch 86: saving model to /home/iiitm/Desktop/march22/saved-model-86-0.02.hdf5\n",
            "380/380 [==============================] - 1096s 3s/step - loss: 0.0197 - acc: 0.9927 - val_loss: 0.3553 - val_acc: 0.9208\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.9933\n",
            "Epoch 87: saving model to /home/iiitm/Desktop/march22/saved-model-87-0.02.hdf5\n",
            "380/380 [==============================] - 1095s 3s/step - loss: 0.0181 - acc: 0.9933 - val_loss: 0.1578 - val_acc: 0.9559\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0197 - acc: 0.9925\n",
            "Epoch 88: saving model to /home/iiitm/Desktop/march22/saved-model-88-0.02.hdf5\n",
            "380/380 [==============================] - 1094s 3s/step - loss: 0.0197 - acc: 0.9925 - val_loss: 0.2702 - val_acc: 0.9459\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.9928\n",
            "Epoch 89: saving model to /home/iiitm/Desktop/march22/saved-model-89-0.02.hdf5\n",
            "380/380 [==============================] - 1092s 3s/step - loss: 0.0203 - acc: 0.9928 - val_loss: 0.3059 - val_acc: 0.9320\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9937\n",
            "Epoch 90: saving model to /home/iiitm/Desktop/march22/saved-model-90-0.02.hdf5\n",
            "380/380 [==============================] - 1097s 3s/step - loss: 0.0164 - acc: 0.9937 - val_loss: 0.2235 - val_acc: 0.9497\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9929\n",
            "Epoch 91: saving model to /home/iiitm/Desktop/march22/saved-model-91-0.02.hdf5\n",
            "380/380 [==============================] - 1098s 3s/step - loss: 0.0192 - acc: 0.9929 - val_loss: 0.2391 - val_acc: 0.9472\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9940\n",
            "Epoch 92: saving model to /home/iiitm/Desktop/march22/saved-model-92-0.02.hdf5\n",
            "380/380 [==============================] - 1096s 3s/step - loss: 0.0157 - acc: 0.9940 - val_loss: 0.1979 - val_acc: 0.9562\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9934\n",
            "Epoch 93: saving model to /home/iiitm/Desktop/march22/saved-model-93-0.02.hdf5\n",
            "380/380 [==============================] - 1096s 3s/step - loss: 0.0178 - acc: 0.9934 - val_loss: 0.2356 - val_acc: 0.9491\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0135 - acc: 0.9953\n",
            "Epoch 94: saving model to /home/iiitm/Desktop/march22/saved-model-94-0.01.hdf5\n",
            "380/380 [==============================] - 1098s 3s/step - loss: 0.0135 - acc: 0.9953 - val_loss: 0.1901 - val_acc: 0.9584\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9928\n",
            "Epoch 95: saving model to /home/iiitm/Desktop/march22/saved-model-95-0.02.hdf5\n",
            "380/380 [==============================] - 1106s 3s/step - loss: 0.0199 - acc: 0.9928 - val_loss: 0.3218 - val_acc: 0.9307\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9953\n",
            "Epoch 96: saving model to /home/iiitm/Desktop/march22/saved-model-96-0.01.hdf5\n",
            "380/380 [==============================] - 1105s 3s/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.3229 - val_acc: 0.9273\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9940\n",
            "Epoch 97: saving model to /home/iiitm/Desktop/march22/saved-model-97-0.02.hdf5\n",
            "380/380 [==============================] - 1105s 3s/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.2996 - val_acc: 0.9351\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9918\n",
            "Epoch 98: saving model to /home/iiitm/Desktop/march22/saved-model-98-0.02.hdf5\n",
            "380/380 [==============================] - 1113s 3s/step - loss: 0.0249 - acc: 0.9918 - val_loss: 0.3342 - val_acc: 0.9323\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0142 - acc: 0.9943\n",
            "Epoch 99: saving model to /home/iiitm/Desktop/march22/saved-model-99-0.01.hdf5\n",
            "380/380 [==============================] - 1109s 3s/step - loss: 0.0142 - acc: 0.9943 - val_loss: 0.1900 - val_acc: 0.9578\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.9931\n",
            "Epoch 100: saving model to /home/iiitm/Desktop/march22/saved-model-100-0.02.hdf5\n",
            "380/380 [==============================] - 1116s 3s/step - loss: 0.0203 - acc: 0.9931 - val_loss: 0.2653 - val_acc: 0.9512\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "H = model3.fit(\n",
        "    training_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f540472c",
      "metadata": {
        "id": "f540472c"
      },
      "outputs": [],
      "source": [
        "model3.save('/home/iiitm/Desktop/march22/sci-model-march22.h5' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ca6f59",
      "metadata": {
        "id": "d8ca6f59"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model1 = load_model('/home/iiitm/Desktop/march22/saved-model-100-0.02.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa0dc34",
      "metadata": {
        "id": "1aa0dc34",
        "outputId": "38345ccf-19f9-47bf-8060-1fefa1615b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5896 images belonging to 3 classes.\n",
            "Accuracy 0.9594640434192673\n"
          ]
        }
      ],
      "source": [
        "test_data_dir='/home/iiitm/Desktop/dataset-new-try-2/path/train/'\n",
        "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_data_generator.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
        "test_labels = test_generator.classes\n",
        "num_classes = len(test_generator.class_indices)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "preds = model1.predict(test_generator)\n",
        "\n",
        "\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
        "\n",
        "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1571446",
      "metadata": {
        "id": "a1571446",
        "outputId": "acee9f27-106f-4f88-b0db-237f64e1bb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 626   52    2]\n",
            " [   8 1286   47]\n",
            " [  17  113 3745]]\n",
            "Classification Report\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       covid-19       0.96      0.92      0.94       680\n",
            "         normal       0.89      0.96      0.92      1341\n",
            "Viral Pneumonia       0.99      0.97      0.98      3875\n",
            "\n",
            "       accuracy                           0.96      5896\n",
            "      macro avg       0.94      0.95      0.95      5896\n",
            "   weighted avg       0.96      0.96      0.96      5896\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "LABELS = [\"Covid-19\",\"Normal\",\"Viral Pneumonia\"]\n",
        "\n",
        "def show_confusion_matrix(validations, predictions):\n",
        "    matrix = confusion_matrix(validations, predictions)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(matrix,\n",
        "                cmap=\"coolwarm\",\n",
        "                linecolor='white',\n",
        "                linewidths=1,\n",
        "                xticklabels=LABELS,\n",
        "                yticklabels=LABELS,\n",
        "                annot=True,\n",
        "                fmt=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.savefig('/home/iiitm/Desktop/march22/confusion-conference.jpg', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "Y_pred =preds\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "show_confusion_matrix(test_generator.classes, y_pred)\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = [\"covid-19\",\"normal\",\"Viral Pneumonia\"]\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0337db48",
      "metadata": {
        "id": "0337db48"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr):\n",
        "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend()\n",
        "    fig1 = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    fig1.savefig('/home/iiitm/Desktop/march22/roc-curve-conference.jpg', dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f68225",
      "metadata": {
        "id": "a7f68225",
        "outputId": "92452ea1-20ec-462e-a207-cf920989e770"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "probs = Y_pred[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_generator.classes, probs, pos_label=1)\n",
        "roc_display =plot_roc_curve(fpr=fpr, tpr=tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55680b9",
      "metadata": {
        "id": "f55680b9"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175d4d1c",
      "metadata": {
        "id": "175d4d1c",
        "outputId": "6e3e081c-0888-4553-b260-760dbffa7b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "plot_model(model1, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b64e31",
      "metadata": {
        "id": "e9b64e31",
        "outputId": "81062b9d-f945-4d5a-e0eb-f9a3436a0f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydot\n",
            "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in ./anaconda3/lib/python3.8/site-packages (from pydot) (2.4.7)\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.4.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "503adf5a",
      "metadata": {
        "id": "503adf5a",
        "outputId": "0682e7e9-2e87-4795-dd18-16db391947a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting graphviz\n",
            "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     || 46 kB 190 kB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: graphviz\n",
            "Successfully installed graphviz-0.19.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27fb979",
      "metadata": {
        "id": "d27fb979"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}