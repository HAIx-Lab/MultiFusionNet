# -*- coding: utf-8 -*-
"""Copy of sci-march-22-final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tkbFwqMezRdGIbhTLwF1vGUuIT_hIgD7
"""

from keras import layers
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D, concatenate, Flatten, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import numpy as np
from keras.applications.resnet_v2 import ResNet50V2
from keras.applications.inception_v3 import InceptionV3

from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate

batch_size = 32
img_height, img_width = 224, 224
input_shape = (img_height, img_width, 3)
epochs = 100
input_tensor = Input(shape = input_shape)

base_model1=ResNet50V2(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)
for layer in base_model1.layers:
  layer.trainable=False
base_model1.summary()

#a=base_model1.get_layer("conv5_block2_3_conv").outputconv3_block3_2_conv
a=base_model1.get_layer("conv3_block3_2_conv").output
a=MaxPooling2D()(a)
a=MaxPooling2D()(a)
b=base_model1.get_layer("conv4_block6_3_conv").output
c=base_model1.get_layer("conv3_block4_3_conv").output
c=MaxPooling2D()(c)
d=base_model1.get_layer("conv2_block3_3_conv").output
d=MaxPooling2D()(d)
d=MaxPooling2D()(d)
print(a.shape)
print(b.shape)
print(c.shape)
print(d.shape)
abcd=concatenate([a,b,c,d], axis=-1)
print(abcd.shape)

y = base_model1.output
conc=concatenate([y,abcd], axis=-1)
conc=BatchNormalization()(conc)
conc=Conv2D(2048, (1,1), activation='relu')(conc)
conc = GlobalAveragePooling2D()(conc)
print(conc.shape)

base_model2=InceptionV3(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)
for layer in base_model2.layers:
  layer.trainable=False
base_model2.summary()

T=concatenate([conc,conc1], axis=-1)
print(T.shape)

def add_specific_features(inputs):
    feature1 = inputs[0]
    feature2 = inputs[1]
    added_features = feature1 + feature2
    return added_features

added_features = Lambda(add_specific_features)([conc, conc1])

from keras.layers import Conv2D, Dropout
print(added_features.shape)
T=Dropout(0.3)(T)

T = Dense(256, activation='relu')(added_features)
predictions1 = Dense(3, activation='softmax')(T)
model3 = Model(inputs=input_tensor,outputs=predictions1)
model3.summary()
model3.compile(loss='CategoricalCrossentropy',optimizer='adam',metrics=['acc'] )

print("Trainable Parameters:")
for layer in model3.trainable_weights:
    print(layer.name)

print(model3)

print("Trainable Layers:")
for layer in model3.layers:
    if layer.trainable:
        print(layer.name)
        print(layer.count_params())
        print('---')

print("Trainable Layers:")
for layer in model3.layers:
    if layer.trainable:
        print(layer.name)
        print(layer.output_shape)
        print(layer.count_params())
        print('---')

for layer in model3.layers:
    if layer.trainable:
        print(layer.name)
        print("Number of Parameters:", layer.count_params())
        if isinstance(layer, Conv2D):
            print("Kernel Size:", layer.kernel_size)
        print("Output Size:", layer.output_shape)
        print()

training_data_dir='/home/iiitm/Desktop/Dataset/train'
training_data_generator = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True)
training_generator = training_data_generator.flow_from_directory(
    training_data_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode="categorical")
validation_data_dir='/home/iiitm/Desktop/Dataset/validation'
validation_data_generator = ImageDataGenerator(rescale=1./255)
validation_generator = validation_data_generator.flow_from_directory(
    validation_data_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode="categorical",
    shuffle=False)

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi

!pip install psutil
!pip install humanize

import psutil
import humanize
import os



# XXX: only one GPU on Colab and isnâ€™t guaranteed

def printm():
    process = psutil.Process(os.getpid())
    print("Gen RAM Free: " + humanize.naturalsize(psutil.virtual_memory().available), " |     Proc size: " + humanize.naturalsize(process.memory_info().rss))

printm()

from keras.callbacks import ModelCheckpoint
filepath = "/home/iiitm/Desktop/march22/saved-model-{epoch:02d}-{loss:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min', save_freq = 'epoch' )

#Training
H = model3.fit(
    training_generator,
    epochs=100,
    validation_data=validation_generator,
    callbacks=[checkpoint])

model3.save('/home/iiitm/Desktop/march22/sci-model-march22.h5' )

from keras.models import load_model
from sklearn.metrics import accuracy_score

model1 = load_model('/home/iiitm/Desktop/march22/saved-model-100-0.02.hdf5')

test_data_dir='/home/iiitm/Desktop/dataset-new-try-2/path/train/'
test_data_generator = ImageDataGenerator(rescale=1./255)
test_generator = test_data_generator.flow_from_directory(
    test_data_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode="categorical",
    shuffle=False)


from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score
test_labels = test_generator.classes
num_classes = len(test_generator.class_indices)
test_labels = to_categorical(test_labels, num_classes=num_classes)
preds = model1.predict(test_generator)


predictions = [i.argmax() for i in preds]
y_true = [i.argmax() for i in test_labels]
cm = confusion_matrix(y_pred=predictions, y_true=y_true)

print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns


LABELS = ["Covid-19","Normal","Viral Pneumonia"]

def show_confusion_matrix(validations, predictions):
    matrix = confusion_matrix(validations, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(matrix,
                cmap="coolwarm",
                linecolor='white',
                linewidths=1,
                xticklabels=LABELS,
                yticklabels=LABELS,
                annot=True,
                fmt="d")
    plt.title("Confusion Matrix")
    plt.ylabel("True Label")
    plt.xlabel("Predicted Label")
    plt.savefig('/home/iiitm/Desktop/march22/confusion-conference.jpg', dpi=300)
    plt.show()

filenames = test_generator.filenames
nb_samples = len(filenames)

Y_pred =preds
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
show_confusion_matrix(test_generator.classes, y_pred)
print(confusion_matrix(test_generator.classes, y_pred))
print('Classification Report')
target_names = ["covid-19","normal","Viral Pneumonia"]
print(classification_report(test_generator.classes, y_pred, target_names=target_names))
# Plot linewidth.
lw = 2

def plot_roc_curve(fpr, tpr):
    plt.plot(fpr, tpr, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    fig1 = plt.gcf()
    plt.show()
    plt.draw()
    fig1.savefig('/home/iiitm/Desktop/march22/roc-curve-conference.jpg', dpi=300)

probs = Y_pred[:, 1]

fpr, tpr, thresholds = roc_curve(test_generator.classes, probs, pos_label=1)
roc_display =plot_roc_curve(fpr=fpr, tpr=tpr)

from keras.utils.vis_utils import plot_model

plot_model(model1, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

pip install pydot

pip install graphviz

